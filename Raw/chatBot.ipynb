{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"chatBot.ipynb","provenance":[],"mount_file_id":"1XPTiF2XUn5HnL98SA47-qxcAbStraXJp","authorship_tag":"ABX9TyO5ynhm0diLWtebqbDUg3W+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"OpzZ5EZcIB2e","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":632},"outputId":"0fffd79d-17e3-4560-c922-82a81167bf1a","executionInfo":{"status":"ok","timestamp":1586891948978,"user_tz":-360,"elapsed":5391,"user":{"displayName":"Md. Rashad Tanjim 1620952042","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9WzP6fUfCZuTHkaH7XzV1tWQO1-9WuE5jOamK=s64","userId":"13917060601554383380"}}},"source":["!pip install tensorflow"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.2.0rc2)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.2)\n","Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0rc0)\n","Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.2.0)\n","Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.28.1)\n","Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n","Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n","Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (3.2.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (46.1.3)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0.post3)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.7.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.0.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.21.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.2.8)\n","Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.0)\n","Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2020.4.5.1)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.24.3)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.8)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OhxQCtzbIIHh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"outputId":"f702ed8c-00d7-4bc1-def6-1427697d5e60","executionInfo":{"status":"ok","timestamp":1586892010445,"user_tz":-360,"elapsed":11809,"user":{"displayName":"Md. Rashad Tanjim 1620952042","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9WzP6fUfCZuTHkaH7XzV1tWQO1-9WuE5jOamK=s64","userId":"13917060601554383380"}}},"source":["!pip install keras\n","!pip install pickle\n","!pip install nltk"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.3.1)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.2)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n","\u001b[31mERROR: Could not find a version that satisfies the requirement pickle (from versions: none)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for pickle\u001b[0m\n","Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"H3xjWzJyIkUp","colab_type":"code","colab":{}},"source":["import nltk\n","from nltk.stem import WordNetLemmatizer\n","lemmatizer = WordNetLemmatizer()\n","import json\n","import pickle"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GwUq13q9JSEA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"1d751010-d1af-4a9e-d9ad-58f635e9dc8f","executionInfo":{"status":"ok","timestamp":1586892209695,"user_tz":-360,"elapsed":2603,"user":{"displayName":"Md. Rashad Tanjim 1620952042","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9WzP6fUfCZuTHkaH7XzV1tWQO1-9WuE5jOamK=s64","userId":"13917060601554383380"}}},"source":["import numpy as np\n","from keras.models import Sequential\n","from keras.layers import Dense, Activation, Dropout\n","from keras.optimizers import SGD\n","import random"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"HSmJERMyJszi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"93a96045-22a9-4fa3-fec3-1ae6665a5972","executionInfo":{"status":"ok","timestamp":1586892384839,"user_tz":-360,"elapsed":1241,"user":{"displayName":"Md. Rashad Tanjim 1620952042","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9WzP6fUfCZuTHkaH7XzV1tWQO1-9WuE5jOamK=s64","userId":"13917060601554383380"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m1nrSzDQJXFs","colab_type":"code","colab":{}},"source":["words=[]\n","classes = []\n","documents = []\n","ignore_words = ['?', '!']\n","data_file = open('/content/drive/My Drive/Datasets/chatBot/intents.json').read()\n","intents = json.loads(data_file)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QKywpVp4LNxf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"outputId":"fa664bea-c247-4a6a-ad9b-56626179ca87","executionInfo":{"status":"ok","timestamp":1586892741288,"user_tz":-360,"elapsed":1652,"user":{"displayName":"Md. Rashad Tanjim 1620952042","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9WzP6fUfCZuTHkaH7XzV1tWQO1-9WuE5jOamK=s64","userId":"13917060601554383380"}}},"source":["nltk.download('punkt')\n","nltk.download('wordnet')"],"execution_count":13,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"3CXwKFB_JaZL","colab_type":"code","colab":{}},"source":["    for intent in intents['intents']:\n","        for pattern in intent['patterns']:\n","            #tokenize each word\n","            w = nltk.word_tokenize(pattern)\n","            words.extend(w)\n","            #add documents in the corpus\n","            documents.append((w, intent['tag']))\n","            # add to our classes list\n","            if intent['tag'] not in classes:\n","                classes.append(intent['tag'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WrBTGvJ5K9Tw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":88},"outputId":"81fac66c-2f44-4b5f-cc90-4be0a16f4941","executionInfo":{"status":"ok","timestamp":1586892750816,"user_tz":-360,"elapsed":2931,"user":{"displayName":"Md. Rashad Tanjim 1620952042","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9WzP6fUfCZuTHkaH7XzV1tWQO1-9WuE5jOamK=s64","userId":"13917060601554383380"}}},"source":["    # lemmatize, lower each word and remove duplicates\n","    words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]\n","    words = sorted(list(set(words)))\n","    # sort classes\n","    classes = sorted(list(set(classes)))\n","    # documents = combination between patterns and intents\n","    print (len(documents), \"documents\")\n","    # classes = intents\n","    print (len(classes), \"classes\", classes)\n","    # words = all words, vocabulary\n","    print (len(words), \"unique lemmatized words\", words)\n","    pickle.dump(words,open('words.pkl','wb'))\n","    pickle.dump(classes,open('classes.pkl','wb'))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["47 documents\n","9 classes ['adverse_drug', 'blood_pressure', 'blood_pressure_search', 'goodbye', 'greeting', 'hospital_search', 'options', 'pharmacy_search', 'thanks']\n","88 unique lemmatized words [\"'s\", ',', 'a', 'adverse', 'all', 'anyone', 'are', 'awesome', 'be', 'behavior', 'blood', 'by', 'bye', 'can', 'causing', 'chatting', 'check', 'could', 'data', 'day', 'detail', 'do', 'dont', 'drug', 'entry', 'find', 'for', 'give', 'good', 'goodbye', 'have', 'hello', 'help', 'helpful', 'helping', 'hey', 'hi', 'history', 'hola', 'hospital', 'how', 'i', 'id', 'is', 'later', 'list', 'load', 'locate', 'log', 'looking', 'lookup', 'management', 'me', 'module', 'nearby', 'next', 'nice', 'of', 'offered', 'open', 'patient', 'pharmacy', 'pressure', 'provide', 'reaction', 'related', 'result', 'search', 'searching', 'see', 'show', 'suitable', 'support', 'task', 'thank', 'thanks', 'that', 'there', 'till', 'time', 'to', 'transfer', 'up', 'want', 'what', 'which', 'with', 'you']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1CQFRbytLVHv","colab_type":"code","colab":{}},"source":["# create our training data\n","training = []\n","# create an empty array for our output\n","output_empty = [0] * len(classes)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RDkjwhPiLh2h","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"f4146799-b63a-4bc7-dfbd-fe9a29e015b6","executionInfo":{"status":"ok","timestamp":1586892922252,"user_tz":-360,"elapsed":652,"user":{"displayName":"Md. Rashad Tanjim 1620952042","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9WzP6fUfCZuTHkaH7XzV1tWQO1-9WuE5jOamK=s64","userId":"13917060601554383380"}}},"source":["for doc in documents:\n","    # initialize our bag of words\n","    bag = []\n","    # list of tokenized words for the pattern\n","    pattern_words = doc[0]\n","    # lemmatize each word - create base word, in attempt to represent related words\n","    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n","    # create our bag of words array with 1, if word match found in current pattern\n","for w in words:\n","    bag.append(1) if w in pattern_words else bag.append(0)\n","    # output is a '0' for each tag and '1' for current tag (for each pattern)\n","    output_row = list(output_empty)\n","    output_row[classes.index(doc[1])] = 1\n","    training.append([bag, output_row])\n","# shuffle our features and turn into np.array\n","random.shuffle(training)\n","training = np.array(training)\n","# create train and test lists. X - patterns, Y - intents\n","train_x = list(training[:,0])\n","train_y = list(training[:,1])\n","print(\"Training data created\")"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Training data created\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ah_hfREsLoQS","colab_type":"code","colab":{}},"source":["# Create model - 3 layers. First layer 128 neurons, second layer 64 neurons and 3rd output layer contains number of neurons\n","# equal to number of intents to predict output intent with softmax\n","model = Sequential()\n","model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(64, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(len(train_y[0]), activation='softmax'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6amux5t3LtgE","colab_type":"code","colab":{}},"source":["# Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n","sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"99uUkxzhMRFx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"f70fc96a-53ca-474f-a746-e093e8a822cc","executionInfo":{"status":"ok","timestamp":1586893025946,"user_tz":-360,"elapsed":16620,"user":{"displayName":"Md. Rashad Tanjim 1620952042","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9WzP6fUfCZuTHkaH7XzV1tWQO1-9WuE5jOamK=s64","userId":"13917060601554383380"}}},"source":["#fitting and saving the model \n","hist = model.fit(np.array(train_x), np.array(train_y), epochs=200, batch_size=5, verbose=1)\n","model.save('chatbot_model.h5', hist)\n","print(\"model created\")"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Epoch 1/200\n","88/88 [==============================] - 2s 20ms/step - loss: 1.0736 - accuracy: 0.7841\n","Epoch 2/200\n","88/88 [==============================] - 0s 625us/step - loss: 0.0123 - accuracy: 1.0000\n","Epoch 3/200\n","88/88 [==============================] - 0s 633us/step - loss: 0.0034 - accuracy: 1.0000\n","Epoch 4/200\n","88/88 [==============================] - 0s 689us/step - loss: 0.0016 - accuracy: 1.0000\n","Epoch 5/200\n","88/88 [==============================] - 0s 657us/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 6/200\n","88/88 [==============================] - 0s 749us/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 7/200\n","88/88 [==============================] - 0s 723us/step - loss: 0.0040 - accuracy: 1.0000\n","Epoch 8/200\n","88/88 [==============================] - 0s 822us/step - loss: 5.4207e-04 - accuracy: 1.0000\n","Epoch 9/200\n","88/88 [==============================] - 0s 619us/step - loss: 3.9497e-04 - accuracy: 1.0000\n","Epoch 10/200\n","88/88 [==============================] - 0s 785us/step - loss: 6.8755e-04 - accuracy: 1.0000\n","Epoch 11/200\n","88/88 [==============================] - 0s 700us/step - loss: 0.0019 - accuracy: 1.0000\n","Epoch 12/200\n","88/88 [==============================] - 0s 658us/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 13/200\n","88/88 [==============================] - 0s 726us/step - loss: 3.5850e-04 - accuracy: 1.0000\n","Epoch 14/200\n","88/88 [==============================] - 0s 690us/step - loss: 0.0024 - accuracy: 1.0000\n","Epoch 15/200\n","88/88 [==============================] - 0s 637us/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 16/200\n","88/88 [==============================] - 0s 632us/step - loss: 5.8310e-04 - accuracy: 1.0000\n","Epoch 17/200\n","88/88 [==============================] - 0s 701us/step - loss: 3.3511e-04 - accuracy: 1.0000\n","Epoch 18/200\n","88/88 [==============================] - 0s 625us/step - loss: 3.8811e-04 - accuracy: 1.0000\n","Epoch 19/200\n","88/88 [==============================] - 0s 702us/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 20/200\n","88/88 [==============================] - 0s 708us/step - loss: 3.4988e-04 - accuracy: 1.0000\n","Epoch 21/200\n","88/88 [==============================] - 0s 884us/step - loss: 1.4906e-04 - accuracy: 1.0000\n","Epoch 22/200\n","88/88 [==============================] - 0s 771us/step - loss: 2.7951e-04 - accuracy: 1.0000\n","Epoch 23/200\n","88/88 [==============================] - 0s 764us/step - loss: 7.8264e-04 - accuracy: 1.0000\n","Epoch 24/200\n","88/88 [==============================] - 0s 676us/step - loss: 6.5798e-04 - accuracy: 1.0000\n","Epoch 25/200\n","88/88 [==============================] - 0s 723us/step - loss: 3.5902e-04 - accuracy: 1.0000\n","Epoch 26/200\n","88/88 [==============================] - 0s 698us/step - loss: 0.0016 - accuracy: 1.0000\n","Epoch 27/200\n","88/88 [==============================] - 0s 785us/step - loss: 6.0652e-04 - accuracy: 1.0000\n","Epoch 28/200\n","88/88 [==============================] - 0s 721us/step - loss: 3.3671e-04 - accuracy: 1.0000\n","Epoch 29/200\n","88/88 [==============================] - 0s 698us/step - loss: 2.3118e-04 - accuracy: 1.0000\n","Epoch 30/200\n","88/88 [==============================] - 0s 693us/step - loss: 4.3533e-04 - accuracy: 1.0000\n","Epoch 31/200\n","88/88 [==============================] - 0s 672us/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 32/200\n","88/88 [==============================] - 0s 708us/step - loss: 2.9047e-04 - accuracy: 1.0000\n","Epoch 33/200\n","88/88 [==============================] - 0s 737us/step - loss: 7.9772e-04 - accuracy: 1.0000\n","Epoch 34/200\n","88/88 [==============================] - 0s 684us/step - loss: 1.3542e-04 - accuracy: 1.0000\n","Epoch 35/200\n","88/88 [==============================] - 0s 714us/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 36/200\n","88/88 [==============================] - 0s 881us/step - loss: 0.0016 - accuracy: 1.0000\n","Epoch 37/200\n","88/88 [==============================] - 0s 717us/step - loss: 4.0901e-04 - accuracy: 1.0000\n","Epoch 38/200\n","88/88 [==============================] - 0s 694us/step - loss: 6.4898e-04 - accuracy: 1.0000\n","Epoch 39/200\n","88/88 [==============================] - 0s 765us/step - loss: 1.0888e-04 - accuracy: 1.0000\n","Epoch 40/200\n","88/88 [==============================] - 0s 634us/step - loss: 6.1816e-04 - accuracy: 1.0000\n","Epoch 41/200\n","88/88 [==============================] - 0s 649us/step - loss: 7.0252e-04 - accuracy: 1.0000\n","Epoch 42/200\n","88/88 [==============================] - 0s 702us/step - loss: 1.6063e-04 - accuracy: 1.0000\n","Epoch 43/200\n","88/88 [==============================] - 0s 693us/step - loss: 6.9968e-04 - accuracy: 1.0000\n","Epoch 44/200\n","88/88 [==============================] - 0s 686us/step - loss: 2.4361e-04 - accuracy: 1.0000\n","Epoch 45/200\n","88/88 [==============================] - 0s 706us/step - loss: 7.6375e-05 - accuracy: 1.0000\n","Epoch 46/200\n","88/88 [==============================] - 0s 719us/step - loss: 1.3651e-04 - accuracy: 1.0000\n","Epoch 47/200\n","88/88 [==============================] - 0s 746us/step - loss: 0.0021 - accuracy: 1.0000\n","Epoch 48/200\n","88/88 [==============================] - 0s 638us/step - loss: 1.8827e-04 - accuracy: 1.0000\n","Epoch 49/200\n","88/88 [==============================] - 0s 664us/step - loss: 4.7951e-04 - accuracy: 1.0000\n","Epoch 50/200\n","88/88 [==============================] - 0s 702us/step - loss: 7.9767e-05 - accuracy: 1.0000\n","Epoch 51/200\n","88/88 [==============================] - 0s 772us/step - loss: 3.0407e-04 - accuracy: 1.0000\n","Epoch 52/200\n","88/88 [==============================] - 0s 883us/step - loss: 3.6424e-04 - accuracy: 1.0000\n","Epoch 53/200\n","88/88 [==============================] - 0s 651us/step - loss: 2.4205e-04 - accuracy: 1.0000\n","Epoch 54/200\n","88/88 [==============================] - 0s 782us/step - loss: 2.8992e-04 - accuracy: 1.0000\n","Epoch 55/200\n","88/88 [==============================] - 0s 699us/step - loss: 1.2823e-04 - accuracy: 1.0000\n","Epoch 56/200\n","88/88 [==============================] - 0s 718us/step - loss: 3.5869e-04 - accuracy: 1.0000\n","Epoch 57/200\n","88/88 [==============================] - 0s 701us/step - loss: 1.1591e-04 - accuracy: 1.0000\n","Epoch 58/200\n","88/88 [==============================] - 0s 722us/step - loss: 0.0084 - accuracy: 1.0000\n","Epoch 59/200\n","88/88 [==============================] - 0s 722us/step - loss: 5.6554e-04 - accuracy: 1.0000\n","Epoch 60/200\n","88/88 [==============================] - 0s 722us/step - loss: 4.8468e-04 - accuracy: 1.0000\n","Epoch 61/200\n","88/88 [==============================] - 0s 847us/step - loss: 3.6191e-04 - accuracy: 1.0000\n","Epoch 62/200\n","88/88 [==============================] - 0s 767us/step - loss: 3.8366e-04 - accuracy: 1.0000\n","Epoch 63/200\n","88/88 [==============================] - 0s 682us/step - loss: 1.3126e-04 - accuracy: 1.0000\n","Epoch 64/200\n","88/88 [==============================] - 0s 648us/step - loss: 4.0651e-05 - accuracy: 1.0000\n","Epoch 65/200\n","88/88 [==============================] - 0s 669us/step - loss: 7.0365e-05 - accuracy: 1.0000\n","Epoch 66/200\n","88/88 [==============================] - 0s 796us/step - loss: 3.2620e-04 - accuracy: 1.0000\n","Epoch 67/200\n","88/88 [==============================] - 0s 839us/step - loss: 4.7400e-04 - accuracy: 1.0000\n","Epoch 68/200\n","88/88 [==============================] - 0s 709us/step - loss: 0.0041 - accuracy: 1.0000\n","Epoch 69/200\n","88/88 [==============================] - 0s 741us/step - loss: 4.8966e-04 - accuracy: 1.0000\n","Epoch 70/200\n","88/88 [==============================] - 0s 740us/step - loss: 6.6546e-05 - accuracy: 1.0000\n","Epoch 71/200\n","88/88 [==============================] - 0s 851us/step - loss: 1.6814e-05 - accuracy: 1.0000\n","Epoch 72/200\n","88/88 [==============================] - 0s 715us/step - loss: 1.6938e-04 - accuracy: 1.0000\n","Epoch 73/200\n","88/88 [==============================] - 0s 704us/step - loss: 4.2308e-04 - accuracy: 1.0000\n","Epoch 74/200\n","88/88 [==============================] - 0s 698us/step - loss: 4.3270e-04 - accuracy: 1.0000\n","Epoch 75/200\n","88/88 [==============================] - 0s 713us/step - loss: 2.9168e-05 - accuracy: 1.0000\n","Epoch 76/200\n","88/88 [==============================] - 0s 687us/step - loss: 3.8163e-05 - accuracy: 1.0000\n","Epoch 77/200\n","88/88 [==============================] - 0s 670us/step - loss: 9.8708e-05 - accuracy: 1.0000\n","Epoch 78/200\n","88/88 [==============================] - 0s 725us/step - loss: 2.6702e-04 - accuracy: 1.0000\n","Epoch 79/200\n","88/88 [==============================] - 0s 719us/step - loss: 1.0564e-04 - accuracy: 1.0000\n","Epoch 80/200\n","88/88 [==============================] - 0s 680us/step - loss: 4.1044e-05 - accuracy: 1.0000\n","Epoch 81/200\n","88/88 [==============================] - 0s 750us/step - loss: 2.5602e-04 - accuracy: 1.0000\n","Epoch 82/200\n","88/88 [==============================] - 0s 950us/step - loss: 2.7633e-04 - accuracy: 1.0000\n","Epoch 83/200\n","88/88 [==============================] - 0s 711us/step - loss: 2.9284e-04 - accuracy: 1.0000\n","Epoch 84/200\n","88/88 [==============================] - 0s 693us/step - loss: 1.1580e-04 - accuracy: 1.0000\n","Epoch 85/200\n","88/88 [==============================] - 0s 768us/step - loss: 7.7603e-05 - accuracy: 1.0000\n","Epoch 86/200\n","88/88 [==============================] - 0s 734us/step - loss: 0.0023 - accuracy: 1.0000\n","Epoch 87/200\n","88/88 [==============================] - 0s 697us/step - loss: 1.6564e-04 - accuracy: 1.0000\n","Epoch 88/200\n","88/88 [==============================] - 0s 721us/step - loss: 2.5873e-04 - accuracy: 1.0000\n","Epoch 89/200\n","88/88 [==============================] - 0s 714us/step - loss: 3.8279e-05 - accuracy: 1.0000\n","Epoch 90/200\n","88/88 [==============================] - 0s 745us/step - loss: 1.1626e-04 - accuracy: 1.0000\n","Epoch 91/200\n","88/88 [==============================] - 0s 734us/step - loss: 1.3165e-04 - accuracy: 1.0000\n","Epoch 92/200\n","88/88 [==============================] - 0s 732us/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 93/200\n","88/88 [==============================] - 0s 690us/step - loss: 8.8274e-05 - accuracy: 1.0000\n","Epoch 94/200\n","88/88 [==============================] - 0s 718us/step - loss: 6.4975e-05 - accuracy: 1.0000\n","Epoch 95/200\n","88/88 [==============================] - 0s 681us/step - loss: 3.4580e-04 - accuracy: 1.0000\n","Epoch 96/200\n","88/88 [==============================] - 0s 752us/step - loss: 9.1738e-04 - accuracy: 1.0000\n","Epoch 97/200\n","88/88 [==============================] - 0s 779us/step - loss: 5.5873e-05 - accuracy: 1.0000\n","Epoch 98/200\n","88/88 [==============================] - 0s 762us/step - loss: 7.3982e-05 - accuracy: 1.0000\n","Epoch 99/200\n","88/88 [==============================] - 0s 713us/step - loss: 6.0608e-05 - accuracy: 1.0000\n","Epoch 100/200\n","88/88 [==============================] - 0s 771us/step - loss: 8.0082e-05 - accuracy: 1.0000\n","Epoch 101/200\n","88/88 [==============================] - 0s 770us/step - loss: 5.6568e-05 - accuracy: 1.0000\n","Epoch 102/200\n","88/88 [==============================] - 0s 868us/step - loss: 2.1175e-04 - accuracy: 1.0000\n","Epoch 103/200\n","88/88 [==============================] - 0s 701us/step - loss: 2.1710e-05 - accuracy: 1.0000\n","Epoch 104/200\n","88/88 [==============================] - 0s 748us/step - loss: 8.4791e-05 - accuracy: 1.0000\n","Epoch 105/200\n","88/88 [==============================] - 0s 731us/step - loss: 5.3975e-04 - accuracy: 1.0000\n","Epoch 106/200\n","88/88 [==============================] - 0s 764us/step - loss: 1.6244e-04 - accuracy: 1.0000\n","Epoch 107/200\n","88/88 [==============================] - 0s 731us/step - loss: 5.0132e-04 - accuracy: 1.0000\n","Epoch 108/200\n","88/88 [==============================] - 0s 674us/step - loss: 1.4725e-04 - accuracy: 1.0000\n","Epoch 109/200\n","88/88 [==============================] - 0s 704us/step - loss: 1.2017e-05 - accuracy: 1.0000\n","Epoch 110/200\n","88/88 [==============================] - 0s 717us/step - loss: 5.9804e-05 - accuracy: 1.0000\n","Epoch 111/200\n","88/88 [==============================] - 0s 940us/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 112/200\n","88/88 [==============================] - 0s 726us/step - loss: 6.5352e-05 - accuracy: 1.0000\n","Epoch 113/200\n","88/88 [==============================] - 0s 630us/step - loss: 1.3435e-05 - accuracy: 1.0000\n","Epoch 114/200\n","88/88 [==============================] - 0s 802us/step - loss: 1.5179e-04 - accuracy: 1.0000\n","Epoch 115/200\n","88/88 [==============================] - 0s 779us/step - loss: 9.6361e-05 - accuracy: 1.0000\n","Epoch 116/200\n","88/88 [==============================] - 0s 697us/step - loss: 8.0767e-05 - accuracy: 1.0000\n","Epoch 117/200\n","88/88 [==============================] - 0s 680us/step - loss: 7.6907e-05 - accuracy: 1.0000\n","Epoch 118/200\n","88/88 [==============================] - 0s 717us/step - loss: 2.5682e-05 - accuracy: 1.0000\n","Epoch 119/200\n","88/88 [==============================] - 0s 700us/step - loss: 1.4030e-04 - accuracy: 1.0000\n","Epoch 120/200\n","88/88 [==============================] - 0s 710us/step - loss: 8.0810e-05 - accuracy: 1.0000\n","Epoch 121/200\n","88/88 [==============================] - 0s 655us/step - loss: 8.5469e-05 - accuracy: 1.0000\n","Epoch 122/200\n","88/88 [==============================] - 0s 722us/step - loss: 0.0022 - accuracy: 1.0000\n","Epoch 123/200\n","88/88 [==============================] - 0s 715us/step - loss: 1.8708e-04 - accuracy: 1.0000\n","Epoch 124/200\n","88/88 [==============================] - 0s 688us/step - loss: 5.7164e-05 - accuracy: 1.0000\n","Epoch 125/200\n","88/88 [==============================] - 0s 687us/step - loss: 6.8785e-05 - accuracy: 1.0000\n","Epoch 126/200\n","88/88 [==============================] - 0s 747us/step - loss: 1.2717e-04 - accuracy: 1.0000\n","Epoch 127/200\n","88/88 [==============================] - 0s 841us/step - loss: 2.1021e-05 - accuracy: 1.0000\n","Epoch 128/200\n","88/88 [==============================] - 0s 735us/step - loss: 1.7225e-05 - accuracy: 1.0000\n","Epoch 129/200\n","88/88 [==============================] - 0s 647us/step - loss: 1.4654e-04 - accuracy: 1.0000\n","Epoch 130/200\n","88/88 [==============================] - 0s 824us/step - loss: 9.9920e-06 - accuracy: 1.0000\n","Epoch 131/200\n","88/88 [==============================] - 0s 750us/step - loss: 9.6033e-05 - accuracy: 1.0000\n","Epoch 132/200\n","88/88 [==============================] - 0s 639us/step - loss: 1.7932e-05 - accuracy: 1.0000\n","Epoch 133/200\n","88/88 [==============================] - 0s 702us/step - loss: 4.5090e-05 - accuracy: 1.0000\n","Epoch 134/200\n","88/88 [==============================] - 0s 698us/step - loss: 5.1990e-05 - accuracy: 1.0000\n","Epoch 135/200\n","88/88 [==============================] - 0s 741us/step - loss: 8.7038e-05 - accuracy: 1.0000\n","Epoch 136/200\n","88/88 [==============================] - 0s 708us/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 137/200\n","88/88 [==============================] - 0s 698us/step - loss: 7.3391e-05 - accuracy: 1.0000\n","Epoch 138/200\n","88/88 [==============================] - 0s 700us/step - loss: 5.6819e-04 - accuracy: 1.0000\n","Epoch 139/200\n","88/88 [==============================] - 0s 653us/step - loss: 1.4115e-05 - accuracy: 1.0000\n","Epoch 140/200\n","88/88 [==============================] - 0s 633us/step - loss: 4.6381e-05 - accuracy: 1.0000\n","Epoch 141/200\n","88/88 [==============================] - 0s 615us/step - loss: 1.1028e-04 - accuracy: 1.0000\n","Epoch 142/200\n","88/88 [==============================] - 0s 764us/step - loss: 1.4471e-05 - accuracy: 1.0000\n","Epoch 143/200\n","88/88 [==============================] - 0s 708us/step - loss: 1.5409e-05 - accuracy: 1.0000\n","Epoch 144/200\n","88/88 [==============================] - 0s 688us/step - loss: 5.6592e-05 - accuracy: 1.0000\n","Epoch 145/200\n","88/88 [==============================] - 0s 742us/step - loss: 2.7924e-05 - accuracy: 1.0000\n","Epoch 146/200\n","88/88 [==============================] - 0s 795us/step - loss: 4.7401e-04 - accuracy: 1.0000\n","Epoch 147/200\n","88/88 [==============================] - 0s 678us/step - loss: 8.0347e-05 - accuracy: 1.0000\n","Epoch 148/200\n","88/88 [==============================] - 0s 705us/step - loss: 8.0963e-05 - accuracy: 1.0000\n","Epoch 149/200\n","88/88 [==============================] - 0s 724us/step - loss: 4.3809e-04 - accuracy: 1.0000\n","Epoch 150/200\n","88/88 [==============================] - 0s 646us/step - loss: 6.0547e-04 - accuracy: 1.0000\n","Epoch 151/200\n","88/88 [==============================] - 0s 662us/step - loss: 3.4474e-06 - accuracy: 1.0000\n","Epoch 152/200\n","88/88 [==============================] - 0s 700us/step - loss: 1.4608e-04 - accuracy: 1.0000\n","Epoch 153/200\n","88/88 [==============================] - 0s 720us/step - loss: 9.7791e-05 - accuracy: 1.0000\n","Epoch 154/200\n","88/88 [==============================] - 0s 623us/step - loss: 1.0172e-05 - accuracy: 1.0000\n","Epoch 155/200\n","88/88 [==============================] - 0s 656us/step - loss: 2.1827e-05 - accuracy: 1.0000\n","Epoch 156/200\n","88/88 [==============================] - 0s 707us/step - loss: 2.3950e-05 - accuracy: 1.0000\n","Epoch 157/200\n","88/88 [==============================] - 0s 676us/step - loss: 4.9639e-05 - accuracy: 1.0000\n","Epoch 158/200\n","88/88 [==============================] - 0s 771us/step - loss: 2.0947e-05 - accuracy: 1.0000\n","Epoch 159/200\n","88/88 [==============================] - 0s 742us/step - loss: 5.8884e-05 - accuracy: 1.0000\n","Epoch 160/200\n","88/88 [==============================] - 0s 714us/step - loss: 2.0126e-05 - accuracy: 1.0000\n","Epoch 161/200\n","88/88 [==============================] - 0s 750us/step - loss: 5.6731e-05 - accuracy: 1.0000\n","Epoch 162/200\n","88/88 [==============================] - 0s 757us/step - loss: 7.5096e-06 - accuracy: 1.0000\n","Epoch 163/200\n","88/88 [==============================] - 0s 673us/step - loss: 2.2251e-05 - accuracy: 1.0000\n","Epoch 164/200\n","88/88 [==============================] - 0s 708us/step - loss: 1.0223e-05 - accuracy: 1.0000\n","Epoch 165/200\n","88/88 [==============================] - 0s 758us/step - loss: 1.5727e-04 - accuracy: 1.0000\n","Epoch 166/200\n","88/88 [==============================] - 0s 702us/step - loss: 4.6914e-04 - accuracy: 1.0000\n","Epoch 167/200\n","88/88 [==============================] - 0s 705us/step - loss: 7.6164e-06 - accuracy: 1.0000\n","Epoch 168/200\n","88/88 [==============================] - 0s 625us/step - loss: 3.1808e-05 - accuracy: 1.0000\n","Epoch 169/200\n","88/88 [==============================] - 0s 645us/step - loss: 4.6042e-04 - accuracy: 1.0000\n","Epoch 170/200\n","88/88 [==============================] - 0s 637us/step - loss: 3.9116e-04 - accuracy: 1.0000\n","Epoch 171/200\n","88/88 [==============================] - 0s 697us/step - loss: 2.8808e-05 - accuracy: 1.0000\n","Epoch 172/200\n","88/88 [==============================] - 0s 622us/step - loss: 4.2397e-06 - accuracy: 1.0000\n","Epoch 173/200\n","88/88 [==============================] - 0s 632us/step - loss: 6.3051e-04 - accuracy: 1.0000\n","Epoch 174/200\n","88/88 [==============================] - 0s 881us/step - loss: 2.3846e-05 - accuracy: 1.0000\n","Epoch 175/200\n","88/88 [==============================] - 0s 797us/step - loss: 8.3974e-05 - accuracy: 1.0000\n","Epoch 176/200\n","88/88 [==============================] - 0s 706us/step - loss: 3.6838e-05 - accuracy: 1.0000\n","Epoch 177/200\n","88/88 [==============================] - 0s 803us/step - loss: 6.1648e-05 - accuracy: 1.0000\n","Epoch 178/200\n","88/88 [==============================] - 0s 672us/step - loss: 1.5729e-04 - accuracy: 1.0000\n","Epoch 179/200\n","88/88 [==============================] - 0s 646us/step - loss: 8.9961e-06 - accuracy: 1.0000\n","Epoch 180/200\n","88/88 [==============================] - 0s 748us/step - loss: 4.8215e-05 - accuracy: 1.0000\n","Epoch 181/200\n","88/88 [==============================] - 0s 637us/step - loss: 5.2346e-05 - accuracy: 1.0000\n","Epoch 182/200\n","88/88 [==============================] - 0s 718us/step - loss: 1.2557e-04 - accuracy: 1.0000\n","Epoch 183/200\n","88/88 [==============================] - 0s 646us/step - loss: 2.9107e-05 - accuracy: 1.0000\n","Epoch 184/200\n","88/88 [==============================] - 0s 635us/step - loss: 1.3352e-05 - accuracy: 1.0000\n","Epoch 185/200\n","88/88 [==============================] - 0s 713us/step - loss: 2.9942e-05 - accuracy: 1.0000\n","Epoch 186/200\n","88/88 [==============================] - 0s 684us/step - loss: 5.5789e-05 - accuracy: 1.0000\n","Epoch 187/200\n","88/88 [==============================] - 0s 615us/step - loss: 1.0138e-04 - accuracy: 1.0000\n","Epoch 188/200\n","88/88 [==============================] - 0s 635us/step - loss: 1.0320e-04 - accuracy: 1.0000\n","Epoch 189/200\n","88/88 [==============================] - 0s 818us/step - loss: 1.2266e-04 - accuracy: 1.0000\n","Epoch 190/200\n","88/88 [==============================] - 0s 783us/step - loss: 3.0521e-05 - accuracy: 1.0000\n","Epoch 191/200\n","88/88 [==============================] - 0s 733us/step - loss: 7.3369e-05 - accuracy: 1.0000\n","Epoch 192/200\n","88/88 [==============================] - 0s 644us/step - loss: 2.6032e-05 - accuracy: 1.0000\n","Epoch 193/200\n","88/88 [==============================] - 0s 777us/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 194/200\n","88/88 [==============================] - 0s 642us/step - loss: 5.6978e-04 - accuracy: 1.0000\n","Epoch 195/200\n","88/88 [==============================] - 0s 618us/step - loss: 2.7171e-05 - accuracy: 1.0000\n","Epoch 196/200\n","88/88 [==============================] - 0s 621us/step - loss: 1.0361e-05 - accuracy: 1.0000\n","Epoch 197/200\n","88/88 [==============================] - 0s 721us/step - loss: 1.1838e-04 - accuracy: 1.0000\n","Epoch 198/200\n","88/88 [==============================] - 0s 649us/step - loss: 3.6954e-06 - accuracy: 1.0000\n","Epoch 199/200\n","88/88 [==============================] - 0s 721us/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 200/200\n","88/88 [==============================] - 0s 675us/step - loss: 2.7115e-05 - accuracy: 1.0000\n","model created\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_MNlSgBqMbBN","colab_type":"code","colab":{}},"source":["import nltk\n","from nltk.stem import WordNetLemmatizer\n","lemmatizer = WordNetLemmatizer()\n","import pickle\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OWDfuIFsMlfN","colab_type":"code","colab":{}},"source":["from keras.models import load_model\n","model = load_model('/content/drive/My Drive/Datasets/chatBot/chatbot_model.h5')\n","import json\n","import random\n","intents = json.loads(open('/content/drive/My Drive/Datasets/chatBot/intents.json').read())\n","words = pickle.load(open('/content/drive/My Drive/Datasets/chatBot/words.pkl','rb'))\n","classes = pickle.load(open('/content/drive/My Drive/Datasets/chatBot/classes.pkl','rb'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CMLD8XstMpgk","colab_type":"code","colab":{}},"source":["def clean_up_sentence(sentence):\n","    # tokenize the pattern - split words into array\n","    sentence_words = nltk.word_tokenize(sentence)\n","    # stem each word - create short form for word\n","    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n","    return sentence_words\n","# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f_CV3u9tM-b4","colab_type":"code","colab":{}},"source":["def bow(sentence, words, show_details=True):\n","    # tokenize the pattern\n","    sentence_words = clean_up_sentence(sentence)\n","    # bag of words - matrix of N words, vocabulary matrix\n","    bag = [0]*len(words) \n","    for s in sentence_words:\n","        for i,w in enumerate(words):\n","            if w == s: \n","                # assign 1 if current word is in the vocabulary position\n","                bag[i] = 1\n","                if show_details:\n","                    print (\"found in bag: %s\" % w)\n","    return(np.array(bag))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4OyyvaeQNBib","colab_type":"code","colab":{}},"source":["def predict_class(sentence, model):\n","    # filter out predictions below a threshold\n","    p = bow(sentence, words,show_details=False)\n","    res = model.predict(np.array([p]))[0]\n","    ERROR_THRESHOLD = 0.25\n","    results = [[i,r] for i,r in enumerate(res) if r>ERROR_THRESHOLD]\n","    # sort by strength of probability\n","    results.sort(key=lambda x: x[1], reverse=True)\n","    return_list = []\n","    for r in results:\n","        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n","    return return_list"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"J10V7kJgNEBq","colab_type":"code","colab":{}},"source":["def getResponse(ints, intents_json):\n","    tag = ints[0]['intent']\n","    list_of_intents = intents_json['intents']\n","    for i in list_of_intents:\n","        if(i['tag']== tag):\n","            result = random.choice(i['responses'])\n","            break\n","    return result"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PZW4-onqNGRa","colab_type":"code","colab":{}},"source":["def chatbot_response(text):\n","    ints = predict_class(text, model)\n","    res = getResponse(ints, intents)\n","    return res"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HHbuZdPwNID_","colab_type":"code","colab":{}},"source":["#Creating GUI with tkinter\n","import tkinter\n","from tkinter import *\n","import sys\n","import os"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XwA95F17NKoS","colab_type":"code","colab":{}},"source":["\n","if os.environ.get('DISPLAY','') == '':\n","    print('no display found. Using :0.0')\n","    os.environ.__setitem__('DISPLAY', ':0.0')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"35T9wGK2NM38","colab_type":"code","colab":{}},"source":["def send():\n","    msg = EntryBox.get(\"1.0\",'end-1c').strip()\n","    EntryBox.delete(\"0.0\",END)\n","\n","    if msg != '':\n","        ChatLog.config(state=NORMAL)\n","        ChatLog.insert(END, \"You: \" + msg + '\\n\\n')\n","        ChatLog.config(foreground=\"#442265\", font=(\"Verdana\", 12 ))\n","    \n","        res = chatbot_response(msg)\n","        ChatLog.insert(END, \"Bot: \" + res + '\\n\\n')\n","            \n","        ChatLog.config(state=DISABLED)\n","        ChatLog.yview(END)\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WT0CadxoNQPR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":351},"outputId":"ba840341-ac47-432b-8c8d-2201b784205d","executionInfo":{"status":"error","timestamp":1586896455707,"user_tz":-360,"elapsed":794,"user":{"displayName":"Md. Rashad Tanjim 1620952042","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9WzP6fUfCZuTHkaH7XzV1tWQO1-9WuE5jOamK=s64","userId":"13917060601554383380"}}},"source":["base = Tk()\n","base.title(\"Hello\")\n","base.geometry(\"400x500\")\n","base.resizable(width=FALSE, height=FALSE)\n","\n","#Create Chat window\n","ChatLog = Text(base, bd=0, bg=\"white\", height=\"8\", width=\"50\", font=\"Arial\",)\n","\n","ChatLog.config(state=DISABLED)\n","\n","#Bind scrollbar to Chat window\n","scrollbar = Scrollbar(base, command=ChatLog.yview, cursor=\"heart\")\n","ChatLog['yscrollcommand'] = scrollbar.set\n","\n","#Create Button to send message\n","SendButton = Button(base, font=(\"Verdana\",12,'bold'), text=\"Send\", width=\"12\", height=5,\n","                    bd=0, bg=\"#32de97\", activebackground=\"#3c9d9b\",fg='#ffffff',\n","                    command= send )\n","\n","#Create the box to enter message\n","EntryBox = Text(base, bd=0, bg=\"white\",width=\"29\", height=\"5\", font=\"Arial\")\n","#EntryBox.bind(\"<Return>\", send)\n","\n","\n","#Place all components on the screen\n","scrollbar.place(x=376,y=6, height=386)\n","ChatLog.place(x=6,y=6, height=386, width=370)\n","EntryBox.place(x=128, y=401, height=90, width=265)\n","SendButton.place(x=6, y=401, height=90)\n","\n","base.mainloop()"],"execution_count":84,"outputs":[{"output_type":"error","ename":"TclError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTclError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-84-80b673e2c2ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hello\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"400x500\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresizable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFALSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFALSE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/tkinter/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, screenName, baseName, className, useTk, sync, use)\u001b[0m\n\u001b[1;32m   2021\u001b[0m                 \u001b[0mbaseName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseName\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2022\u001b[0m         \u001b[0minteractive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2023\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tkinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreenName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwantobjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2024\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2025\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loadtk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTclError\u001b[0m: couldn't connect to display \":0.0\""]}]},{"cell_type":"code","metadata":{"id":"W-Xnn78FX_Sx","colab_type":"code","colab":{}},"source":["!export DISPLAY=:0.0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NFJkOn-NZO6c","colab_type":"code","colab":{}},"source":["import matplotlib\n","matplotlib.use('Agg')\n","import matplotlib.pylab as plt\n","fig = plt.figure()\n","ax = fig.add_subplot(111)\n","ax.plot([1,2,3])\n","fig.savefig('test.png')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SfpBVCbrZPXT","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}